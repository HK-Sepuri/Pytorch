{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values of the images to be between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = (train_images, train_labels), (test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the labels to integers\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PARAMETER* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def param_initialization(nx, nh1, nh2, nh3, nh4, ny):\n",
    "    W = {\n",
    "        'w1': np.random.randn(nh1, nx) * 0.01,\n",
    "        'w2': np.random.randn(nh2, nh1) * 0.01,\n",
    "        'w3': np.random.randn(nh3, nh2) * 0.01,\n",
    "        'w4': np.random.randn(nh4, nh3) * 0.01,\n",
    "        'w5': np.random.randn(ny, nh4) * 0.01\n",
    "    }\n",
    "    \n",
    "    b = {\n",
    "        'b1': np.zeros((nh1, 1)),\n",
    "        'b2': np.zeros((nh2, 1)),\n",
    "        'b3': np.zeros((nh3, 1)),\n",
    "        'b4': np.zeros((nh4, 1)),\n",
    "        'b5': np.zeros((ny, 1))\n",
    "    }\n",
    "\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
    "    return exps / np.sum(exps, axis=0, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_prop(x, W, b):\n",
    "    A = {}\n",
    "    Z = {}\n",
    "    \n",
    "    Z['z1'] = np.dot(W['w1'], x) + b['b1']\n",
    "    A['a1'] = relu(Z['z1'])\n",
    "\n",
    "    Z['z2'] = np.dot(W['w2'], A['a1']) + b['b2']\n",
    "    A['a2'] = relu(Z['z2'])\n",
    "\n",
    "    Z['z3'] = np.dot(W['w3'], A['a2']) + b['b3']\n",
    "    A['a3'] = relu(Z['z3'])\n",
    "\n",
    "    Z['z4'] = np.dot(W['w4'], A['a3']) + b['b4']\n",
    "    A['a4'] = relu(Z['z4'])\n",
    "\n",
    "    Z['z5'] = np.dot(W['w5'], A['a4']) + b['b5']\n",
    "    A['a5'] = softmax(Z['z5'])\n",
    "\n",
    "    return Z, A\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(r):\n",
    "    return np.where(r > 0, 1, 0)\n",
    "\n",
    "\n",
    "def softmax_derivative(r):\n",
    "    return softmax(r) * (1 - softmax(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def backward(W, b, x, Z, A, y, lr):\n",
    "    m = x.shape[1]  # number of examples\n",
    "\n",
    "    dL_dz5 = A['a5'] - y\n",
    "    dL_dw5 = (1 / m) * np.dot(dL_dz5, A['a4'].T)\n",
    "    dL_db5 = (1 / m) * np.sum(dL_dz5, axis=1, keepdims=True)\n",
    "\n",
    "    dL_da4 = np.dot(W['w5'].T, dL_dz5)\n",
    "    dL_dz4 = dL_da4 * relu_derivative(Z['z4'])\n",
    "    dL_dw4 = (1 / m) * np.dot(dL_dz4, A['a3'].T)\n",
    "    dL_db4 = (1 / m) * np.sum(dL_dz4, axis=1, keepdims=True)\n",
    "\n",
    "    dL_da3 = np.dot(W['w4'].T, dL_dz4)\n",
    "    dL_dz3 = dL_da3 * relu_derivative(Z['z3'])\n",
    "    dL_dw3 = (1 / m) * np.dot(dL_dz3, A['a2'].T)\n",
    "    dL_db3 = (1 / m) * np.sum(dL_dz3, axis=1, keepdims=True)\n",
    "\n",
    "    dL_da2 = np.dot(W['w3'].T, dL_dz3)\n",
    "    dL_dz2 = dL_da2 * relu_derivative(Z['z2'])\n",
    "    dL_dw2 = (1 / m) * np.dot(dL_dz2, A['a1'].T)\n",
    "    dL_db2 = (1 / m) * np.sum(dL_dz2, axis=1, keepdims=True)\n",
    "\n",
    "    dL_da1 = np.dot(W['w2'].T, dL_dz2)\n",
    "    dL_dz1 = dL_da1 * relu_derivative(Z['z1'])\n",
    "    dL_dw1 = (1 / m) * np.dot(dL_dz1, x.T)\n",
    "    dL_db1 = (1 / m) * np.sum(dL_dz1, axis=1, keepdims=True)\n",
    "\n",
    "    # Update weights\n",
    "    W['w1'] -= lr * dL_dw1\n",
    "    W['w2'] -= lr * dL_dw2\n",
    "    W['w3'] -= lr * dL_dw3\n",
    "    W['w4'] -= lr * dL_dw4\n",
    "    W['w5'] -= lr * dL_dw5\n",
    "\n",
    "    # Update biases\n",
    "    b['b1'] -= lr * dL_db1\n",
    "    b['b2'] -= lr * dL_db2\n",
    "    b['b3'] -= lr * dL_db3\n",
    "    b['b4'] -= lr * dL_db4\n",
    "    b['b5'] -= lr * dL_db5\n",
    "\n",
    "    return W, b    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train, y_train, W, b, lr, epochs, batch_size):\n",
    "    n_batches = int(x_train.shape[0] / batch_size)  # Calculate the number of batches\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(x_train.shape[0]):\n",
    "            \n",
    "            x = x_train[i:i+1].T  # Select a batch of examples\n",
    "            y = y_train[i:i+1].T  # Select the corresponding labels\n",
    "            \n",
    "            # Forward propagation for the batch\n",
    "            Z, A = fwd_prop(x, W, b)\n",
    "            \n",
    "            # Backward propagation for the batch\n",
    "            W, b = backward(W, b, x, Z, A, y, lr)\n",
    "        \n",
    "        # Prediction and accuracy calculation for the entire training set (for simplicity)\n",
    "        _, A_last = fwd_prop(x_train.T, W, b)\n",
    "        predictions = predict(A_last)\n",
    "        accuracy = np.mean(predictions == np.argmax(y_train.T, axis=0)) * 100  # Assuming y_train is one-hot encoded\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{epochs} complete. Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(A_last):\n",
    "    return np.argmax(A_last, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "# Assuming you have x_test similar to x_train\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_20768\\2106022798.py:5: RuntimeWarning: invalid value encountered in subtract\n",
      "  exps = np.exp(x - np.max(x, axis=0, keepdims=True))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 complete. Accuracy: 100.00%\n",
      "Epoch 2/5 complete. Accuracy: 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[190], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      4\u001b[0m W,b \u001b[38;5;241m=\u001b[39m param_initialization(\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[189], line 11\u001b[0m, in \u001b[0;36mmodel\u001b[1;34m(x_train, y_train, W, b, lr, epochs, batch_size)\u001b[0m\n\u001b[0;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m y_train[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# Select the corresponding labels\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Forward propagation for the batch\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m Z, A \u001b[38;5;241m=\u001b[39m \u001b[43mfwd_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Backward propagation for the batch\u001b[39;00m\n\u001b[0;32m     14\u001b[0m W, b \u001b[38;5;241m=\u001b[39m backward(W, b, x, Z, A, y, lr)\n",
      "Cell \u001b[1;32mIn[162], line 5\u001b[0m, in \u001b[0;36mfwd_prop\u001b[1;34m(x, W, b)\u001b[0m\n\u001b[0;32m      2\u001b[0m A \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      3\u001b[0m Z \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 5\u001b[0m Z[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m A[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m relu(Z[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      8\u001b[0m Z[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw2\u001b[39m\u001b[38;5;124m'\u001b[39m], A[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma1\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "A = {}\n",
    "lr = 0.01\n",
    "epochs = 5\n",
    "W,b = param_initialization(784, 256, 128, 64, 32, 10)\n",
    "model(x_train, y_train, W, b, lr, epochs,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(x_test, y_test, W, b):\n",
    "    # Forward propagation on test data\n",
    "    _, A_last = fwd_prop(x_test.T, W, b)\n",
    "    \n",
    "    # Prediction\n",
    "    predictions = predict(A_last)\n",
    "    \n",
    "    # Directly compare predictions with y_test if y_test is not one-hot encoded\n",
    "    accuracy = np.mean(predictions == y_test) * 100  # Adjusted line\n",
    "    return accuracy\n",
    "\n",
    "# Assuming x_test and y_test are your test dataset and labels\n",
    "accuracy = check_accuracy(x_test, y_test, W, b)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_stuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
